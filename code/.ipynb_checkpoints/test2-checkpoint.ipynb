{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a353efd8-478c-4b20-b795-9c412e09768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hisha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# import torch\n",
    "\n",
    "import nltk, csv, collections\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.sparse import hstack\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6e1f5-e7e9-49bd-bee2-c3819e3916c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "datafolder = '../../data/hateful_memes/'\n",
    "train = datafolder+'train.jsonl'\n",
    "test = datafolder+'test_seen.jsonl'\n",
    "dev = datafolder+'dev_seen.jsonl'\n",
    "# Load the data from the JSON file\n",
    "df_train = pd.read_json(train, lines = True)\n",
    "df_dev = pd.read_json(dev, lines = True)\n",
    "df_test = pd.read_json(test, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b482e6-6820-4955-9996-3d4f39627555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "    text = row['text']\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        pos = token.pos_\n",
    "        lemma = token.lemma_\n",
    "        tokens.append((token.text, lemma, pos))\n",
    "    row['tokens'] = \" \".join([t[0] for t in tokens])\n",
    "    row['lemmas'] = \" \".join([t[1] for t in tokens])\n",
    "    row['upos'] = \" \".join([t[2] for t in tokens])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9160ee45-fe0f-499a-b937-a7bb8eb90f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.apply(preprocess_row, axis=1)\n",
    "df_dev = df_dev.apply(preprocess_row, axis=1)\n",
    "df_test = df_test.apply(preprocess_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeabd12-3529-43f5-9dc6-7eb573b7d38d",
   "metadata": {},
   "source": [
    "# basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7daaeeec-1e82-41b2-abe5-aca8cf839c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer01 = CountVectorizer(tokenizer=lambda x: x.split(), analyzer='word', ngram_range=(1, 1)) # to build n-grams (n=1-5) from the word ==> BoW\n",
    "                \n",
    "X_train = vectorizer01.fit_transform(df_train.tokens)\n",
    "X_dev = vectorizer01.transform(df_dev.tokens) \n",
    "X_test = vectorizer01.transform(df_test.tokens)\n",
    "\n",
    "Y_train = df_train.label.values\n",
    "Y_dev = df_dev.label.values\n",
    "Y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "28644b43-7737-4158-82a8-5d773e09bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = LinearSVC(max_iter=100000) # parameter C was selected based on grid search\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "Y_pred = clf_svc.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fbe5340-3206-4efc-a094-4c2864d61510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text classifier results using only n1 BoW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.54845</td>\n",
       "      <td>0.539414</td>\n",
       "      <td>0.518258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "0    0.54845  0.539414  0.518258"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(Y_dev, Y_pred, average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "print(\"Text classifier results using only n1 BoW\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab35b7-8e07-42cd-b662-864c3b788ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48c03b6f-18c9-450a-bcac-ee14c8b061e8",
   "metadata": {},
   "source": [
    "# advanced SVM \n",
    "#### - pos_fw_emo = representation of the text through POS tags, function words, and emotion words (from this representation n-grams (n=1-3) are built, see vectorize below)\n",
    "#### - count = number of emotion words in a text\n",
    "#### - emotion_associations = emotion associations from the NRC emotion lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a1c573a-5299-4ef1-898b-6d54cfe2df15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smut', ['disgust', 'fear', 'negative']),\n",
       " ('expletive', ['anger', 'negative']),\n",
       " ('greeting', ['positive', 'surprise'])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the NRC emotion lexicon into a dictionary with emotion words and corresponding associations\n",
    "lexicon = '../../data/hateful_memes/nrc-lexicon-en.txt' # path to the NRC emotion lexicon on Google drive\n",
    "emotions = {}\n",
    "for line in open(lexicon).read().split('\\n'):\t\n",
    "    emotion_word = line.split('\\t')[0]\n",
    "    emotion = line.split('\\t')[1]\n",
    "    association = line.split('\\t')[2]\n",
    "    if association == \"1\":\n",
    "        if emotion_word in emotions:\n",
    "            emotions[emotion_word].append(emotion)\n",
    "        else:\n",
    "            emotions[emotion_word] = [emotion] \n",
    "\n",
    "list(emotions.items())[:3] # print first 3 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53d9dbcf-ba11-4078-8a80-cbaeee4efdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features as described in the paper:\n",
    "# - pos_fw_emo = representation of the text through POS tags, function words, and emotion words (from this representation n-grams (n=1-3) are built, see vectorize below)\n",
    "# - count = number of emotion words in a text\n",
    "# - emotion_associations = emotion associations from the NRC emotion lexicon\n",
    "\n",
    "fw_list = ['ADP', 'AUX', 'CCONJ', 'DET', 'NUM', 'PART', 'PRON', 'SCONJ'] # POS tags that correspond to function words\n",
    "\n",
    "def get_feats_en(upos, lemmas):\t\n",
    "    pos_fw_emo = []\n",
    "    count = 0\n",
    "    emotion_associations = []\n",
    "    for i, lemma in enumerate(lemmas.split()):\t\t\n",
    "        if lemma.lower() in emotions:\n",
    "            pos_fw_emo.append(lemma)\n",
    "            count += 1\n",
    "            emotion_associations.append(emotions[lemma.lower()])     \n",
    "        else:\n",
    "            if upos.split()[i] in fw_list:\n",
    "                pos_fw_emo.append(lemma)\n",
    "            else:\n",
    "                pos_fw_emo.append(upos.split()[i])\n",
    "    emotion_associations = [emo for sublist in emotion_associations for emo in sublist]\n",
    "    return pd.Series([' '.join(pos_fw_emo), count, ' '.join(emotion_associations)])\n",
    "\n",
    "df_train[['pos_fw_emo', 'count', 'emotion_associations']] = df_train.apply(lambda x: get_feats_en(x['upos'], x['lemmas']), axis=1) \n",
    "df_dev[['pos_fw_emo', 'count', 'emotion_associations']] = df_dev.apply(lambda x: get_feats_en(x['upos'], x['lemmas']), axis=1) \n",
    "df_test[['pos_fw_emo', 'count', 'emotion_associations']] = df_test.apply(lambda x: get_feats_en(x['upos'], x['lemmas']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "05f4f438-5528-4226-83e6-002a1cf26443",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(tokenizer=lambda x: x.split(), analyzer='word', ngram_range=(1, 3)) # to build n-grams (n=1-3) from the pos_fw_emo representation\n",
    "vectorizer2 = CountVectorizer(tokenizer=lambda x: x.split(), analyzer='word', ngram_range=(1, 1)) # unigrams of emotion associations\n",
    "vectorizer3 = CountVectorizer(tokenizer=lambda x: x.split(), analyzer='word', ngram_range=(1, 1)) \n",
    "\n",
    "\n",
    "# combine the features\n",
    "X_train = hstack((vectorizer1.fit_transform(df_train.pos_fw_emo), vectorizer2.fit_transform(df_train.emotion_associations), df_train[['count']].values, vectorizer03.fit_transform(df_train.tokens)), format='csr') \n",
    "X_dev = hstack((vectorizer1.transform(df_dev.pos_fw_emo), vectorizer2.transform(df_dev.emotion_associations), df_dev[['count']].values, vectorizer03.transform(df_dev.tokens)), format='csr') \n",
    "X_test = hstack((vectorizer1.transform(df_test.pos_fw_emo), vectorizer2.transform(df_test.emotion_associations), df_test[['count']].values, vectorizer03.transform(df_test.tokens)), format='csr') \n",
    "\n",
    "Y_train = df_train.label.values\n",
    "Y_dev = df_dev.label.values\n",
    "Y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51ac4329-574c-4fa9-965d-902786d2015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = LinearSVC(max_iter=100000) # parameter C was selected based on grid search\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "Y_pred = clf_svc.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01ea1467-308c-46fc-8f69-5bdf15b4989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543518</td>\n",
       "      <td>0.528476</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "0   0.543518  0.528476  0.485714"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(Y_dev, Y_pred, average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f645e3a-461c-4c3e-b58b-329f7666dc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d12f26f1-b33f-4cb3-9386-066bc5344d7d",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca56e5-ef1a-441b-baeb-1a38d1f7e0f1",
   "metadata": {},
   "source": [
    "### using wordembeddings from bert Hate-speech-CNERG/dehatebert-mono-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b15e88b7-c3ae-4dcb-a1df-4081a7158ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Hate-speech-CNERG/dehatebert-mono-english were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\")\n",
    "model = AutoModel.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\").to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a function to get the vector representation of a text\n",
    "def get_text_vector(text, tokenizer = tokenizer, model = model):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Move the inputs to the device\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Get the output of the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the last hidden state of the BERT model\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "    # Get the mean of the last hidden state across all tokens\n",
    "    mean_last_hidden_state = torch.mean(last_hidden_state, dim=1)\n",
    "\n",
    "    # Move the mean_last_hidden_state to the cpu and convert to a numpy array\n",
    "    return mean_last_hidden_state.cpu().numpy()\n",
    "\n",
    "\n",
    "# Get the vectors for each string in the list\n",
    "def get_vectors(dataframe):\n",
    "    vector_list = []\n",
    "    for text in dataframe.text.to_list():\n",
    "        text_vector = get_text_vector(text)\n",
    "        vector_list.append(text_vector)\n",
    "    return vector_list\n",
    "\n",
    "\n",
    "# Convert the vector_list to a numpy array and print the shape\n",
    "# vectors = np.array(vector_list)\n",
    "# print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5a24cff-1bb7-4ae3-8a10-21e6820832d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = get_vectors(df_train)\n",
    "dev_vectors = get_vectors(df_dev)\n",
    "test_vectors = get_vectors(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08de7faa-592e-4adb-84bc-889f0f87eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train.label.values\n",
    "Y_dev = df_dev.label.values\n",
    "Y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05e00141-b338-44d8-99ae-4c946b373db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543518</td>\n",
       "      <td>0.528476</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "0   0.543518  0.528476  0.485714"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = LinearSVC(max_iter=100000) # parameter C was selected based on grid search\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "Y_pred = clf_svc.predict(X_dev)\n",
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(Y_dev, Y_pred, average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dd3e3-311d-4a67-b9e7-28c84d9e52f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d082b190-46be-47f0-a877-dae8c90daba6",
   "metadata": {},
   "source": [
    "### Trial 2: using Hate-speech-CNERG/dehatebert-mono-english directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b4393326-8b90-4284-a468-c9314bc7326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/dehatebert-mono-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c8624b9-53be-46ab-9cbd-b4b416e85785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NON_HATE'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(df_train.text[0])[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4089779d-58da-4a21-871e-ca8c46ebb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['predicted'] = df_train.text.apply(lambda x: 0 if model(x)[0]['label'] == 'NON_HATE' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ceaab62-7714-44f6-8738-82796d241de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655363</td>\n",
       "      <td>0.580117</td>\n",
       "      <td>0.566793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "0   0.655363  0.580117  0.566793"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(df_train['label'], df_train['predicted'], average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb955fb-937c-44e3-a12f-e266f73803e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47426d12-c36c-4acd-917c-92fe22d0b704",
   "metadata": {
    "tags": []
   },
   "source": [
    "### trial 3: fine tuning bert_base_cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b9d1f-2018-4df1-b76d-b20bf26b3085",
   "metadata": {},
   "source": [
    "##### First we just test the performance of the pre-trained model without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb3eab4-f31c-4147-9d2d-7cb12f060483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id            img  label  \\\n",
      "0  42953  img/42953.png      0   \n",
      "1  23058  img/23058.png      0   \n",
      "2  13894  img/13894.png      0   \n",
      "3  37408  img/37408.png      0   \n",
      "4  82403  img/82403.png      0   \n",
      "\n",
      "                                                text  predicted_label  \n",
      "0   its their character not their color that matters                0  \n",
      "1  don't be afraid to love again everyone is not ...                0  \n",
      "2                           putting bows on your pet                0  \n",
      "3  i love everything and everybody! except for sq...                0  \n",
      "4  everybody loves chocolate chip cookies, even h...                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Set up GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# # Load dataframe\n",
    "# df_train = pd.read_csv('train.csv')\n",
    "\n",
    "# Define function to classify text\n",
    "def classify_text(text):\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "\n",
    "    # Make prediction with model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "\n",
    "    # Get predicted label\n",
    "    predicted_label = torch.argmax(output[0], dim=1).item()\n",
    "\n",
    "    # Return predicted label\n",
    "    return predicted_label\n",
    "\n",
    "# Apply function to df_train['text'] column\n",
    "df_train['predicted_label'] = df_train['text'].apply(lambda x: classify_text(x))\n",
    "\n",
    "# Print results\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12619e4f-22cc-4348-ae29-5db64b651ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall        F1\n",
       "0   0.322412     0.5  0.392032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(df_train['label'], df_train['predicted_label'], average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf5b53-dded-4f44-9407-24cfb43c23b2",
   "metadata": {},
   "source": [
    "##### And here we tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a1fbd30-8283-43a5-8a89-91bde801f3be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1 with average training loss of 0.5795393059576365.\n",
      "Finished epoch 2 with average training loss of 0.46517806304128545.\n",
      "Finished epoch 3 with average training loss of 0.3902210938583191.\n",
      "Finished epoch 4 with average training loss of 0.3300486235018063.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with average training loss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Evaluate model on validation data\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m df_val \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     70\u001b[0m attention_masks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'val.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Set up GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Load dataframe\n",
    "# df_train = pd.read_csv('train.csv')\n",
    "\n",
    "# Tokenize input texts and create input tensors\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_train['text'], df_train['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_sampler = RandomSampler(dataset)\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Fine-tune model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_masks = batch[1].to(device)\n",
    "        batch_labels = batch[2].to(device)\n",
    "        model.zero_grad()\n",
    "        loss, logits = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks, labels=batch_labels, return_dict=False)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Finished epoch {epoch+1} with average training loss of {avg_train_loss}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a136816d-cf63-4f01-89a7-6ccf8ee6b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.545703125\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "# df_val = pd.read_csv('val.csv')\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_dev['text'], df_dev['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "    \n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_sampler = SequentialSampler(dataset)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "for batch in val_dataloader:\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_masks = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "        _, logits = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks, labels=batch_labels, return_dict=False)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = batch_labels.to('cpu').numpy()\n",
    "    # print(logits, label_ids)\n",
    "    total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "print(f\"Validation accuracy: {avg_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2d4684-2f6c-4c9e-8f74-1c88a7297d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.545703125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.85      0.65       253\n",
      "           1       0.59      0.23      0.33       247\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.56      0.54      0.49       500\n",
      "weighted avg       0.56      0.54      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate model on validation data\n",
    "# df_val = pd.read_csv('val.csv')\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_dev['text'], df_dev['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_sampler = SequentialSampler(dataset)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "preds = []\n",
    "for batch in val_dataloader:\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_masks = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = batch_labels.to('cpu').numpy()\n",
    "    preds.extend(np.argmax(logits, axis=1))\n",
    "    total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "print(f\"Validation accuracy: {avg_val_accuracy}\")\n",
    "\n",
    "# Print precision, recall, and F1-score\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f5656-1640-424a-8bac-ac1f63c8cd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
