{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca903e6e-323e-42c4-acfc-8ed32008e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hisha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.sparse import hstack\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "from utils import *\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff7386e-2d84-4fb3-bd4a-b6b8b0870251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "datafolder = '../../data/hateful_memes/'\n",
    "train = datafolder+'train_with_features.csv'\n",
    "test = datafolder+'test_with_features.csv'\n",
    "dev = datafolder+'dev_with_features.csv'\n",
    "df_train = pd.read_csv(train, skip_blank_lines=False)\n",
    "df_dev = pd.read_csv(dev, skip_blank_lines=False)\n",
    "df_test = pd.read_csv(test, skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab76e52-6b66-4bc7-bf04-044ce4c4b28c",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d11d0-5d0e-4947-a54f-a598f7b62417",
   "metadata": {},
   "source": [
    "### using wordembeddings from bert Hate-speech-CNERG/dehatebert-mono-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7196ff68-010b-4544-b022-08b2b00d49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Hate-speech-CNERG/dehatebert-mono-english were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\")\n",
    "model = AutoModel.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\").to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# get word embeddings of the sentences in the the text column of text\n",
    "train_vectors = utils.get_vectors(df_train.text.to_list(), tokenizer, model)\n",
    "dev_vectors = utils.get_vectors(df_dev.text.to_list(), tokenizer, model)\n",
    "test_vectors = utils.get_vectors(df_test.text.to_list(), tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6933d47e-8de8-4a2f-b539-8f598f04d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train.label.values\n",
    "Y_dev = df_dev.label.values\n",
    "Y_test = df_test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca5214f5-9a57-4b60-9aa0-0bfa388b70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603766</td>\n",
       "      <td>0.558024</td>\n",
       "      <td>0.505507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "0   0.603766  0.558024  0.505507"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = SVC(kernel='linear', max_iter=100000) # parameter C was selected based on grid search\n",
    "clf_svc.fit(train_vectors, Y_train)\n",
    "Y_pred = clf_svc.predict(dev_vectors)\n",
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(Y_dev, Y_pred, average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fea82f4b-0b02-4531-a80d-1b90d9cbbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred2 = clf_svc.predict(test_vectors)\n",
    "df_dev['hatebert_vectors'] = Y_pred\n",
    "df_test['hatebert_vectors'] = Y_pred2\n",
    "\n",
    "df_dev.to_csv(datafolder+'dev_with_features.csv', index=False)\n",
    "df_test.to_csv(datafolder+'test_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83904cb5-b8fb-4d2a-b3c0-6f4c8b089e89",
   "metadata": {},
   "source": [
    "### Trial 2: using Hate-speech-CNERG/dehatebert-mono-english directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf08092-2409-4c29-b78d-9b5a45cde628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"text-classification\", model=\"Hate-speech-CNERG/dehatebert-mono-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9349371-7fef-4398-9131-d309f2e668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['predicted'] = df_train.text.apply(lambda x: 0 if model(x)[0]['label'] == 'NON_HATE' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf2f61-0af4-4c14-b608-1946f01f46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['hatebert_direct'] = df_dev.text.apply(lambda x: 0 if model(x)[0]['label'] == 'NON_HATE' else 1)\n",
    "df_test['hatebert_direct'] = df_test.text.apply(lambda x: 0 if model(x)[0]['label'] == 'NON_HATE' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f678b3-37c4-48bc-ab82-3425e5afc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv(datafolder+'dev_with_features.csv', index=False)\n",
    "df_test.to_csv(datafolder+'test_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e192a-d870-4e9a-8468-f5368ab1e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(df_dev['label'], df_dev['hatebert_direct'], average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4ab6a-cf34-49da-89b9-abffaf2de7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8128d91-931c-49b6-9816-6a5ae05264dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### trial 3: fine tuning bert_base_cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c030e7-f198-4aff-8b42-7199fb0904cf",
   "metadata": {},
   "source": [
    "##### First we just test the performance of the pre-trained model without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc55c0c-4565-499b-8a17-61ed9aa16041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id            img  label  \\\n",
      "0  42953  img/42953.png      0   \n",
      "1  23058  img/23058.png      0   \n",
      "2  13894  img/13894.png      0   \n",
      "3  37408  img/37408.png      0   \n",
      "4  82403  img/82403.png      0   \n",
      "\n",
      "                                                text  \\\n",
      "0   its their character not their color that matters   \n",
      "1  don't be afraid to love again everyone is not ...   \n",
      "2                           putting bows on your pet   \n",
      "3  i love everything and everybody! except for sq...   \n",
      "4  everybody loves chocolate chip cookies, even h...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0   its their character not their color that matters   \n",
      "1  do n't be afraid to love again everyone is not...   \n",
      "2                           putting bows on your pet   \n",
      "3  i love everything and everybody ! except for s...   \n",
      "4  everybody loves chocolate chip cookies , even ...   \n",
      "\n",
      "                                              lemmas  \\\n",
      "0    its their character not their color that matter   \n",
      "1  do not be afraid to love again everyone be not...   \n",
      "2                                put bow on your pet   \n",
      "3  I love everything and everybody ! except for s...   \n",
      "4  everybody love chocolate chip cookie , even hi...   \n",
      "\n",
      "                                                upos  \\\n",
      "0            PRON PRON NOUN PART PRON NOUN PRON VERB   \n",
      "1  AUX PART AUX ADJ PART VERB ADV PRON AUX PART A...   \n",
      "2                            VERB NOUN ADP PRON NOUN   \n",
      "3  PRON VERB PRON CCONJ PRON PUNCT SCONJ ADP NOUN...   \n",
      "4            PRON VERB NOUN NOUN NOUN PUNCT ADV NOUN   \n",
      "\n",
      "                                          pos_fw_emo  count  \\\n",
      "0            its their NOUN not their NOUN that VERB      0   \n",
      "1  do not be afraid to love ADV everyone be not l...      2   \n",
      "2                              VERB NOUN on your pet      1   \n",
      "3  I love everything and everybody PUNCT except f...      2   \n",
      "4  everybody love chocolate NOUN NOUN PUNCT ADV NOUN      2   \n",
      "\n",
      "                               emotion_associations  sentiment_score  \\\n",
      "0                                               NaN         0.997626   \n",
      "1                        fear negative joy positive         0.998164   \n",
      "2                                          negative         0.997667   \n",
      "3  joy positive anger disgust fear negative sadness         0.997727   \n",
      "4      joy positive anticipation joy positive trust         0.998391   \n",
      "\n",
      "                 intent  predicted_label  \n",
      "0         to be admired                0  \n",
      "1           to be loved                0  \n",
      "2  to show appreciation                0  \n",
      "3         to be a lover                0  \n",
      "4           to eat them                0  \n"
     ]
    }
   ],
   "source": [
    "# Set up GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# # Load dataframe\n",
    "# df_train = pd.read_csv('train.csv')\n",
    "\n",
    "# Define function to classify text\n",
    "def classify_text(text):\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "\n",
    "    # Make prediction with model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "\n",
    "    # Get predicted label\n",
    "    predicted_label = torch.argmax(output[0], dim=1).item()\n",
    "\n",
    "    # Return predicted label\n",
    "    return predicted_label\n",
    "\n",
    "# Apply function to df_train['text'] column\n",
    "df_train['predicted_label'] = df_train['text'].apply(lambda x: classify_text(x))\n",
    "\n",
    "# Print results\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70d8659-9474-4453-994a-873eed86e6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.392032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall        F1\n",
       "0   0.322412     0.5  0.392032"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(df_train['label'], df_train['predicted_label'], average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af24de4-1295-417a-8edf-185006908f23",
   "metadata": {},
   "source": [
    "##### And here we tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8240d29e-5f45-41c5-84d0-d3da01d95f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1 with average training loss of 0.5794730981937924.\n",
      "Finished epoch 2 with average training loss of 0.47785264040742603.\n",
      "Finished epoch 3 with average training loss of 0.40099139349128965.\n",
      "Finished epoch 4 with average training loss of 0.3310820721650034.\n",
      "Finished epoch 5 with average training loss of 0.28724317031359314.\n",
      "Finished epoch 6 with average training loss of 0.24667913720179768.\n",
      "Finished epoch 7 with average training loss of 0.2228365904910672.\n",
      "Finished epoch 8 with average training loss of 0.20607491077056952.\n",
      "Finished epoch 9 with average training loss of 0.19099854277376843.\n",
      "Finished epoch 10 with average training loss of 0.177815996467563.\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Load dataframe\n",
    "# df_train = pd.read_csv('train.csv')\n",
    "\n",
    "# Tokenize input texts and create input tensors\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_train['text'], df_train['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_sampler = RandomSampler(dataset)\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 10\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Fine-tune model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_masks = batch[1].to(device)\n",
    "        batch_labels = batch[2].to(device)\n",
    "        model.zero_grad()\n",
    "        loss, logits = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks, labels=batch_labels, return_dict=False)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Finished epoch {epoch+1} with average training loss of {avg_train_loss}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13e3c551-55f7-4454-959e-25a74ab5b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.562890625\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "# df_val = pd.read_csv('val.csv')\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_dev['text'], df_dev['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "    \n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_sampler = SequentialSampler(dataset)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "for batch in val_dataloader:\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_masks = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "        _, logits = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks, labels=batch_labels, return_dict=False)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = batch_labels.to('cpu').numpy()\n",
    "    # print(logits, label_ids)\n",
    "    total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "print(f\"Validation accuracy: {avg_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c88fb5e-7312-47e1-a81b-42eae7e216af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.562890625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.84      0.66       253\n",
      "           1       0.62      0.26      0.37       247\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.58      0.55      0.51       500\n",
      "weighted avg       0.58      0.56      0.52       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate model on validation data\n",
    "# df_val = pd.read_csv('val.csv')\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_dev['text'], df_dev['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_sampler = SequentialSampler(dataset)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "preds = []\n",
    "for batch in val_dataloader:\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_masks = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = batch_labels.to('cpu').numpy()\n",
    "    preds.extend(np.argmax(logits, axis=1))\n",
    "    total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "print(f\"Validation accuracy: {avg_val_accuracy}\")\n",
    "\n",
    "# Print precision, recall, and F1-score\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a758c4b0-f8c6-4ef2-b3fe-44cb6b3bc8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hisha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5888671875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67       510\n",
      "           1       0.64      0.32      0.43       490\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.60      0.57      0.55      1000\n",
      "weighted avg       0.60      0.58      0.55      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate model on validation data\n",
    "# df_val = pd.read_csv('val.csv')\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for text, label in zip(df_test['text'], df_test['label']):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    labels.append(int(label))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_sampler = SequentialSampler(dataset)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "preds2 = []\n",
    "for batch in val_dataloader:\n",
    "    batch_input_ids = batch[0].to(device)\n",
    "    batch_attention_masks = batch[1].to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = batch_labels.to('cpu').numpy()\n",
    "    preds2.extend(np.argmax(logits, axis=1))\n",
    "    total_val_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "print(f\"Validation accuracy: {avg_val_accuracy}\")\n",
    "\n",
    "# Print precision, recall, and F1-score\n",
    "print(classification_report(labels, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c99619-a4e3-4f67-a890-cc8a1ab813d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['bert_base_cased_finetuned'] = preds\n",
    "df_test['bert_base_cased_finetuned'] = preds2\n",
    "\n",
    "df_dev.to_csv(datafolder+'dev_with_features.csv', index=False)\n",
    "df_test.to_csv(datafolder+'test_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd24e40-2aeb-4cec-99c3-292c66522d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
