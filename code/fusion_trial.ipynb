{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1ee5dcb-7ab6-4ee9-a8a6-bc5fc95eb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from scipy.sparse import hstack\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset, Image, concatenate_datasets\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96d38778-6b39-4d2d-b0e2-b6070ed503c6",
   "metadata": {},
   "source": [
    "Block (c) concatenates the three decision vectors.Finally, \n",
    "block (d) is the classiﬁcation modulecomprised of four fully connected layers. \n",
    "    The sizeof the ﬁrst layer is equal to K times the number of classes N.\n",
    "    The second layer equals (4×N) which is greater than the size of the ﬁrst layer to again avoidthe Bottleneck phenomenon.\n",
    "    The size of the thirdlayer is 2×N, which is associated with a dropout.\n",
    "    The fourth (last) layer is a softmax function of a size equal to the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db5f077a-1a2d-44ab-ad8b-58c7056694b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flattening = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(4, 8)\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flattening(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "def fuse_proba(arr1, arr2):\n",
    "    assert arr1.size == arr2.size\n",
    "    return np.hstack([arr1, arr2])\n",
    "\n",
    "def train(X, Y, batch_size = 64, num_epochs = 100):\n",
    "    # input_dim =  X.shape[1]\n",
    "    model = MLP()\n",
    "    criterion = nn.BCELoss()  # binary cross-entropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.Tensor(X), torch.Tensor(Y))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Training loop:\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader: \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.view(-1, 1)  # reshape labels to match output shape\n",
    "            loss = criterion(torch.unsqueeze(outputs[:, 1], dim=1), labels)  # calculate the loss using binary cross-entropy with the positive class probability and the binary label\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    return model\n",
    "\n",
    "def evaluate(model, X, Y):\n",
    "    test_dataset = TensorDataset(torch.Tensor(X), torch.Tensor(Y))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in test_loader:\n",
    "            test_outputs = model(inputs)  # Get the model's predictions\n",
    "            _, predicted = torch.max(test_outputs.data, 1)  # Get the predicted class by choosing the class with highest probability\n",
    "            predicted_probabilities = test_outputs[:, 1]  # Get the probability for the positive class\n",
    "\n",
    "    # Apply a threshold to the predicted probabilities to obtain binary predictions\n",
    "    threshold = 0.5\n",
    "    binary_predictions = (predicted_probabilities > threshold).float()\n",
    "\n",
    "    return binary_predictions\n",
    "\n",
    "def performance(preds, labels):\n",
    "    results = []\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, preds)\n",
    "    AUROC = auc(fpr, tpr)\n",
    "    results = {'f1_score': report['macro avg']['f1-score'], \n",
    "               'precision': report['macro avg']['precision'], \n",
    "               'recall': report['macro avg']['recall'], \n",
    "               'accuracy': report['accuracy'], \n",
    "               'AUROC': AUROC\n",
    "              }\n",
    "    df_results = pd.DataFrame(results, index=[0]) \n",
    "    df_results = df_results.sort_values(by='AUROC', ascending=False)\n",
    "    return df_results\n",
    "\n",
    "def late_fuse_MLP(X_train, Y_train, X_test, Y_test):\n",
    "    # print('training ...')\n",
    "    model = train(X_train, Y_train)\n",
    "    # print('predicting')\n",
    "    pred = evaluate(model, X_test, Y_test)\n",
    "    results_df = performance(pred, Y_test)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4a150ece-edbb-4eda-b577-1124c588dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_fuse_MLP(X_train, Y_train, X_test, Y_test):\n",
    "    # print('training ...')\n",
    "    model = train(X_train, Y_train)\n",
    "    # print('predicting')\n",
    "    pred = evaluate(model, X_test, Y_test)\n",
    "    results_df = performance(pred, Y_test)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473d0d0-351d-485f-a241-889cefb65401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e9048acd-8803-4d7a-9fae-2a9383a3f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.rand(1000,2)\n",
    "arr2 = np.random.rand(1000,2)\n",
    "Y = np.random.randint(2, size=1000)\n",
    "arr = fuse_proba(arr1, arr2)\n",
    "\n",
    "test_arr1 = np.random.rand(500,2)\n",
    "test_arr2 = np.random.rand(500,2)\n",
    "test_arr = fuse_proba(test_arr1, test_arr2)\n",
    "Y_test = np.random.randint(2, size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3ceb47fe-96be-4cc3-9f5d-0b8cbc22f0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531741</td>\n",
       "      <td>0.555883</td>\n",
       "      <td>0.547323</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.547323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall  accuracy     AUROC\n",
       "0  0.531741   0.555883  0.547323     0.552  0.547323"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_fuse_MLP(arr, Y, test_arr, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33ebee-e9d5-441b-afff-1817ede7f0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
