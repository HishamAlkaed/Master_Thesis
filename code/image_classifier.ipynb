{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81fe956c-0e27-45ec-9638-94f13a3163a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "import torch\n",
    "from datasets import load_dataset, Image\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5463e4-8a1e-476a-a6fe-b9beea5ce656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "datafolder = '../../data/hateful_memes/'\n",
    "train = datafolder+'train_with_features.csv'\n",
    "test = datafolder+'test_with_features.csv'\n",
    "dev = datafolder+'dev_with_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698040f2-1d1f-4a70-b82e-cbf45ed7fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Hisha/.cache/huggingface/datasets/csv/default-a188762e54a0d8f3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095f5bdea88c41fa91810d54758467a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files={\"train\": train, \"validation\": dev, \"test\": test},  num_proc=8).cast_column(\"img\", Image(decode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5ec8e-a59f-4c59-8dba-dc1651c4e3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Initialize image processor and ResNet model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, otherwise use CPU\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetModel.from_pretrained(\"microsoft/resnet-50\").to(device)\n",
    "def get_image_vectors(dataset, split):\n",
    "    # Initialize list to store outputs\n",
    "    outputs_list = []\n",
    "\n",
    "    # Iterate through all images in the dataset\n",
    "    for i in range(len(dataset[split]['img'])):\n",
    "\n",
    "        # Open image using PIL\n",
    "        image = Image.open(datafolder+dataset[split]['img'][i]['path'])\n",
    "        \n",
    "        # Check image format and convert if necessary\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        # Check image size and resize if necessary\n",
    "        if image.size != (224, 224):\n",
    "            image = image.resize((224, 224))\n",
    "            \n",
    "        # Preprocess image using the image processor\n",
    "        inputs = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Pass image through the ResNet model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Append the last hidden state to the outputs list\n",
    "        outputs_list.append(outputs.last_hidden_state.to(device))\n",
    "    return outputs_list\n",
    "        # outputs_list.append(outputs.last_hidden_state.numpy().flatten().tolist())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96b43f-324d-4c93-9eb0-a0e0bc40d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img = get_image_vectors(dataset, 'train')\n",
    "# dev_img = get_image_vectors(dataset, 'validation')\n",
    "# test_img = get_image_vectors(dataset, 'test')\n",
    "\n",
    "# torch.save(train_img, 'train_img_tensors.pt')\n",
    "# torch.save(dev_img, 'dev_img_tensors.pt')\n",
    "# torch.save(test_img, 'test_img_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43130be3-6490-4f95-b8fb-38c56ae143cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = torch.load('train_img_tensors.pt')\n",
    "dev_img = torch.load('dev_img_tensors.pt')\n",
    "test_img = torch.load('test_img_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9dc139-902e-42fd-bf4a-cb1c40c7cc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X = [np.array(x.cpu()).flatten() for x in train_img]\n",
    "dev_X = [np.array(x.cpu()).flatten() for x in dev_img]\n",
    "test_X = [np.array(x.cpu()).flatten() for x in test_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8260cc39-8f54-4972-bc5b-dfd7cf288c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(dataset['train']['label'])\n",
    "Y_dev = np.asarray(dataset['validation']['label'])\n",
    "Y_test = np.asarray(dataset['test']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6fb2a-5058-4a2f-9417-415cf5f69bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC(kernel='rbf', max_iter = 100000) # parameter C was selected based on grid search\n",
    "clf_svc.fit(train_X, Y_train)\n",
    "Y_pred = clf_svc.predict(dev_X)\n",
    "results = pd.DataFrame(\n",
    "    [list(precision_recall_fscore_support(Y_dev, Y_pred, average='macro')[:3])],\n",
    "    columns=['precision', 'recall', 'F1'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5081b63-ca74-448f-88e4-1f6ed92cb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred2 = clf_svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ed007-ff9c-4d48-bf31-f4a44001d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv(dev, keep_default_na=False)\n",
    "df_test = pd.read_csv(test, keep_default_na=False)\n",
    "\n",
    "df_dev['ResNet_svm_rbf_kernel'] = Y_pred\n",
    "df_test['ResNet_svm_rbf_kernel'] = Y_pred_2\n",
    "\n",
    "df_dev.to_csv(datafolder+'dev_with_features.csv', index=False)\n",
    "df_test.to_csv(datafolder+'test_with_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da7905-30aa-4c4d-8463-d8a67a584af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev = pd.read_csv(dev, keep_default_na=False)\n",
    "# df_test = pd.read_csv(test, keep_default_na=False)\n",
    "\n",
    "# df_dev['ResNet_svm_rbf_kernel'] = Y_pred\n",
    "# df_test['ResNet_svm_rbf_kernel'] = Y_pred_2\n",
    "\n",
    "# df_dev.to_csv(datafolder+'dev_with_features.csv', index=False)\n",
    "# df_test.to_csv(datafolder+'test_with_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
